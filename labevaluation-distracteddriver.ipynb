{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing the necessary libraries \n\nimport numpy as np\nimport pandas as pd\nimport os \nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport random\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D,Conv2D,Dense,Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.381403Z","iopub.execute_input":"2022-03-15T14:14:12.381681Z","iopub.status.idle":"2022-03-15T14:14:12.387747Z","shell.execute_reply.started":"2022-03-15T14:14:12.381650Z","shell.execute_reply":"2022-03-15T14:14:12.386986Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# setting up directories\n\nbase_dir = '../input/state-farm-distracted-driver-detection/' # base directory\nimages_dir = os.path.join(base_dir,'imgs/')                   # images directory\ntest_dir = os.path.join(base_dir,'imgs/test/')                # test directory\ntrain_dir = os.path.join(base_dir,'imgs/train/')              # train directory\n\nimgs_list = pd.read_csv(os.path.join(base_dir,'driver_imgs_list.csv'))  # images list csv \nsample_sub = pd.read_csv(os.path.join(base_dir,'sample_submission.csv'))       # sample submission","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.394049Z","iopub.execute_input":"2022-03-15T14:14:12.394890Z","iopub.status.idle":"2022-03-15T14:14:12.527841Z","shell.execute_reply.started":"2022-03-15T14:14:12.394845Z","shell.execute_reply":"2022-03-15T14:14:12.527148Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"len(imgs_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.529479Z","iopub.execute_input":"2022-03-15T14:14:12.529741Z","iopub.status.idle":"2022-03-15T14:14:12.536321Z","shell.execute_reply.started":"2022-03-15T14:14:12.529708Z","shell.execute_reply":"2022-03-15T14:14:12.535655Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"All the images are in jpg format, we will have to","metadata":{}},{"cell_type":"code","source":"# checking the classes avaliable \nclasses = imgs_list['classname'].unique()\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.537556Z","iopub.execute_input":"2022-03-15T14:14:12.537980Z","iopub.status.idle":"2022-03-15T14:14:12.547482Z","shell.execute_reply.started":"2022-03-15T14:14:12.537943Z","shell.execute_reply":"2022-03-15T14:14:12.546816Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"This is each class desc given in question\n\n*    c0: safe driving\n*    c1: texting - right\n*    c2: talking on the phone - right\n*    c3: texting - left\n*    c4: talking on the phone - left\n*    c5: operating the radio\n*    c6: drinking\n*    c7: reaching behind\n*    c8: hair and makeup\n*    c9: talking to passenger\n","metadata":{}},{"cell_type":"code","source":"#adding class desfination according to the given question\n\nclass_def = {\n    \n    'c0': 'safe driving',\n    'c1': 'texting - right',\n    'c2': 'talking on the phone - right',\n    'c3': 'texting - left',\n    'c4': 'talking on the phone - left',\n    'c5': 'operating the radio',\n    'c6': 'drinking',\n    'c7': 'reaching behind',\n    'c8': 'hair and makeup',\n    'c9': 'talking to passenger'\n\n}\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.549037Z","iopub.execute_input":"2022-03-15T14:14:12.549360Z","iopub.status.idle":"2022-03-15T14:14:12.554919Z","shell.execute_reply.started":"2022-03-15T14:14:12.549273Z","shell.execute_reply":"2022-03-15T14:14:12.554157Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#checking class distribution\n\nimgs_list.groupby('classname')['img'].count().sort_values().plot(kind='bar')\nplt.ylabel('Number of images')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:15:57.957578Z","iopub.execute_input":"2022-03-15T14:15:57.957852Z","iopub.status.idle":"2022-03-15T14:15:58.389766Z","shell.execute_reply.started":"2022-03-15T14:15:57.957822Z","shell.execute_reply":"2022-03-15T14:15:58.389075Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"imgs_list.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.556950Z","iopub.execute_input":"2022-03-15T14:14:12.557482Z","iopub.status.idle":"2022-03-15T14:14:12.568427Z","shell.execute_reply.started":"2022-03-15T14:14:12.557445Z","shell.execute_reply":"2022-03-15T14:14:12.567691Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#randomly printing 30 images\n#since all the images are in jpg format\n#using PIL Image library for printing the images\n\nfig = plt.figure(figsize=(30,20)) # image size               \n\nfor i in range(30):\n    random_img = random.randint(0,imgs_list.shape[0])\n    img = Image.open(os.path.join(base_dir,'imgs/train/')+str(imgs_list.loc[random_img,'classname']+'/')\n                    + str(imgs_list.loc[random_img,'img']))\n    fig.add_subplot(6,5,i+1)\n    plt.imshow(img)\n    plt.title(class_def[imgs_list.loc[random_img,'classname']])\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:14:12.569793Z","iopub.execute_input":"2022-03-15T14:14:12.570160Z","iopub.status.idle":"2022-03-15T14:14:16.096646Z","shell.execute_reply.started":"2022-03-15T14:14:12.570125Z","shell.execute_reply":"2022-03-15T14:14:16.095832Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# size of each image\n\nimg = Image.open('../input/state-farm-distracted-driver-detection/imgs/test/img_1.jpg')\nprint(img.size)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:15:25.982840Z","iopub.execute_input":"2022-03-15T14:15:25.983126Z","iopub.status.idle":"2022-03-15T14:15:26.001312Z","shell.execute_reply.started":"2022-03-15T14:15:25.983094Z","shell.execute_reply":"2022-03-15T14:15:26.000583Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Now we have analysed the data, moving onto generation matrices of every image","metadata":{}},{"cell_type":"code","source":"# creating the train data generator and test data generator\n \nimage_size = (128,128)  # image shape\nbatch_size = 32\nval_size = 0.2\n\n# initialising image generator\ntrain_data_gen = ImageDataGenerator(rescale=1./127,validation_split= val_size)\ntest_data_gen = ImageDataGenerator(rescale=1./127)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:18:36.859527Z","iopub.execute_input":"2022-03-15T14:18:36.859779Z","iopub.status.idle":"2022-03-15T14:18:36.864637Z","shell.execute_reply.started":"2022-03-15T14:18:36.859750Z","shell.execute_reply":"2022-03-15T14:18:36.863961Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# after initialising image generator, extract the images from the directories defined above\n\n\ntrain_generator = train_data_gen.flow_from_directory(train_dir,\n                                                     target_size = image_size,\n                                                     batch_size = batch_size,\n                                                     seed=42, \n                                                     shuffle=True,\n                                                     subset='training')\n\nval_generator =  train_data_gen.flow_from_directory(train_dir,\n                                               target_size = image_size,\n                                               batch_size = batch_size,\n                                               seed=42, \n                                               shuffle=True,\n                                               subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:23:25.065452Z","iopub.execute_input":"2022-03-15T14:23:25.065712Z","iopub.status.idle":"2022-03-15T14:23:48.177632Z","shell.execute_reply.started":"2022-03-15T14:23:25.065682Z","shell.execute_reply":"2022-03-15T14:23:48.176888Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# check the data for one batch\n\nfor data_batch,label_batch in train_generator:\n    print(data_batch.shape)   # train batch\n    print(label_batch.shape)  # label batch\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:23:57.899551Z","iopub.execute_input":"2022-03-15T14:23:57.900358Z","iopub.status.idle":"2022-03-15T14:23:58.219423Z","shell.execute_reply.started":"2022-03-15T14:23:57.900314Z","shell.execute_reply":"2022-03-15T14:23:58.218581Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"* 32 images in each batch\n* 128X128: Each image size\n* 3 represents RGB layer","metadata":{}},{"cell_type":"markdown","source":"Formulated the matrices, now building the model","metadata":{}},{"cell_type":"code","source":"model1 = Sequential()                                                  # creating a sequential model\nmodel1.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3))) # taking units of 32 and filter of 3x3\nmodel1.add(MaxPooling2D(2,2))                                          # maxpool layer with 2x2 filter   \nmodel1.add(Conv2D(64,(3,3),activation='relu'))                         # taking units of 64 and filter of 3x3\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Conv2D(128,(3,3),activation='relu'))                        # taking units of 128 and filter of 3x3\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Conv2D(256,(3,3),activation='relu'))                        # taking units of 256 and filter of 3x3\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Flatten())                                                  # flattening the data to feed into to Dense layer\nmodel1.add(Dense(4096,activation='relu'))                              # taking units of 4096\nmodel1.add(Dense(2048,activation='relu'))                              # taking units of 2048\nmodel1.add(Dense(1024,activation='relu'))                              # taking units of 1024\nmodel1.add(Dense(512,activation='relu'))                               # taking units of 512 \nmodel1.add(Dense(128,activation='relu'))                               # taking units of 128\nmodel1.add(Dense(10,activation='softmax'))                             # output later with units of 10 since 10 labels\n\nmodel1.summary() # to print summary of model architecture","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:02:16.860280Z","iopub.execute_input":"2022-03-15T15:02:16.860748Z","iopub.status.idle":"2022-03-15T15:02:16.966813Z","shell.execute_reply.started":"2022-03-15T15:02:16.860705Z","shell.execute_reply":"2022-03-15T15:02:16.966081Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()                                                  # creating a sequential model\nmodel2.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3))) # taking units of 32 and filter of 3x3\nmodel2.add(MaxPooling2D(2,2))                                          # maxpool layer with 2x2 filter   \nmodel2.add(Conv2D(64,(3,3),activation='relu'))                         # taking units of 64 and filter of 3x3\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Conv2D(128,(3,3),activation='relu'))                        # taking units of 128 and filter of 3x3\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Conv2D(256,(3,3),activation='relu'))                        # taking units of 256 and filter of 3x3\nmodel2.add(MaxPooling2D(2,2))\nmodel2.add(Conv2D(512,(3,3),activation='relu'))                        # taking units of 512 and filter of 3x3\nmodel2.add(MaxPooling2D(2,2))    \nmodel2.add(Flatten())                                                  # flattening the data to feed into to Dense layer\nmodel2.add(Dense(1024,activation='relu'))                              # taking units of 1024\nmodel2.add(Dense(512,activation='relu'))                               # taking units of 512 \nmodel2.add(Dense(128,activation='relu'))                               # taking units of 128\nmodel2.add(Dense(10,activation='softmax'))                             # output later with units of 10 since 10 labels\n\nmodel2.summary() # to print summary of model architecture","metadata":{"execution":{"iopub.status.busy":"2022-03-15T14:51:32.583685Z","iopub.execute_input":"2022-03-15T14:51:32.584263Z","iopub.status.idle":"2022-03-15T14:51:32.683413Z","shell.execute_reply.started":"2022-03-15T14:51:32.584221Z","shell.execute_reply":"2022-03-15T14:51:32.682577Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model3 = Sequential()                                                  # creating a sequential model\nmodel3.add(Conv2D(32,(2,2),activation='relu',input_shape=(128,128,3))) # taking units of 32 and filter of 3x3\nmodel3.add(MaxPooling2D(2,2))                                          # maxpool layer with 2x2 filter   \nmodel3.add(Conv2D(64,(2,2),activation='relu'))                         # taking units of 64 and filter of 3x3\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Conv2D(128,(2,2),activation='relu'))                        # taking units of 128 and filter of 3x3\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Conv2D(256,(2,2),activation='relu'))                        # taking units of 256 and filter of 3x3\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Conv2D(512,(2,2),activation='relu'))                        # taking units of 512 and filter of 3x3\nmodel3.add(MaxPooling2D(2,2)) \nmodel3.add(Flatten())                                                  # flattening the data to feed into to Dense layer\nmodel3.add(Dense(2048,activation='relu'))                              # taking units of 1024\nmodel3.add(Dense(1024,activation='relu'))                              # taking units of 1024\nmodel3.add(Dense(512,activation='relu'))                               # taking units of 512 \nmodel3.add(Dense(128,activation='relu'))                               # taking units of 128\nmodel3.add(Dense(10,activation='softmax'))                             # output later with units of 10 since 10 labels\n\nmodel3.summary() # to print summary of model architecture\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:04:21.246774Z","iopub.execute_input":"2022-03-15T15:04:21.247394Z","iopub.status.idle":"2022-03-15T15:04:21.353295Z","shell.execute_reply.started":"2022-03-15T15:04:21.247352Z","shell.execute_reply":"2022-03-15T15:04:21.352495Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model1.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:06:42.371483Z","iopub.execute_input":"2022-03-15T15:06:42.372336Z","iopub.status.idle":"2022-03-15T15:06:42.402384Z","shell.execute_reply.started":"2022-03-15T15:06:42.372285Z","shell.execute_reply":"2022-03-15T15:06:42.401387Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nhistory = model1.fit(train_generator,\n         steps_per_epoch=240,\n         epochs=epochs,\n         validation_data=val_generator,\n         validation_steps=60\n        )","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:07:02.366548Z","iopub.execute_input":"2022-03-15T15:07:02.367506Z","iopub.status.idle":"2022-03-15T15:20:33.305566Z","shell.execute_reply.started":"2022-03-15T15:07:02.367459Z","shell.execute_reply":"2022-03-15T15:20:33.304851Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"model2.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:21:23.309978Z","iopub.execute_input":"2022-03-15T15:21:23.310758Z","iopub.status.idle":"2022-03-15T15:21:23.321206Z","shell.execute_reply.started":"2022-03-15T15:21:23.310705Z","shell.execute_reply":"2022-03-15T15:21:23.320471Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nhistory2 = model2.fit(train_generator,\n         steps_per_epoch=240,\n         epochs=epochs,\n         validation_data=val_generator,\n         validation_steps=60\n        )","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:21:37.787274Z","iopub.execute_input":"2022-03-15T15:21:37.787531Z","iopub.status.idle":"2022-03-15T15:34:42.877530Z","shell.execute_reply.started":"2022-03-15T15:21:37.787502Z","shell.execute_reply":"2022-03-15T15:34:42.876748Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"model3.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:34:42.891429Z","iopub.execute_input":"2022-03-15T15:34:42.891709Z","iopub.status.idle":"2022-03-15T15:34:42.902145Z","shell.execute_reply.started":"2022-03-15T15:34:42.891650Z","shell.execute_reply":"2022-03-15T15:34:42.901458Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nhistory3 = model3.fit(train_generator,\n         steps_per_epoch=240,\n         epochs=epochs,\n         validation_data=val_generator,\n         validation_steps=60\n        )","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:34:42.905455Z","iopub.execute_input":"2022-03-15T15:34:42.906072Z","iopub.status.idle":"2022-03-15T15:47:48.933632Z","shell.execute_reply.started":"2022-03-15T15:34:42.906031Z","shell.execute_reply":"2022-03-15T15:47:48.932680Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"Comparing model 1,2 and 3. Model 1 gave the best accuracy","metadata":{}},{"cell_type":"code","source":"tr_loss = history.history['loss']\ntr_accuracy = history.history['accuracy']\n\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:54:41.857358Z","iopub.execute_input":"2022-03-15T15:54:41.857717Z","iopub.status.idle":"2022-03-15T15:54:41.862024Z","shell.execute_reply.started":"2022-03-15T15:54:41.857674Z","shell.execute_reply":"2022-03-15T15:54:41.861169Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"epchs = list(range(1,len(tr_loss)+1))\nplt.plot(epchs,tr_loss,label='Train')\nplt.plot(epchs,val_loss,label='Test')\nplt.title(\"Training and Validation loss\")\nplt.legend()\nplt.show()\n\n\nplt.plot(epchs,tr_accuracy,label='Train')\nplt.plot(epchs,val_accuracy,label='Test')\nplt.title(\"Training and Validation accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:55:11.719955Z","iopub.execute_input":"2022-03-15T15:55:11.720496Z","iopub.status.idle":"2022-03-15T15:55:12.068517Z","shell.execute_reply.started":"2022-03-15T15:55:11.720459Z","shell.execute_reply":"2022-03-15T15:55:12.067759Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_data = test_gen.flow_from_directory(\n    images_dir,\n    shuffle = False,\n    target_size = image_size,\n    classes = ['test'],\n    batch_size = 32\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:55:49.146773Z","iopub.execute_input":"2022-03-15T15:55:49.147484Z","iopub.status.idle":"2022-03-15T15:56:18.043247Z","shell.execute_reply.started":"2022-03-15T15:55:49.147447Z","shell.execute_reply":"2022-03-15T15:56:18.042522Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"preds = model1.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T15:56:18.044721Z","iopub.execute_input":"2022-03-15T15:56:18.046068Z","iopub.status.idle":"2022-03-15T16:10:17.528294Z","shell.execute_reply.started":"2022-03-15T15:56:18.046024Z","shell.execute_reply":"2022-03-15T16:10:17.527453Z"},"trusted":true},"execution_count":98,"outputs":[]}]}